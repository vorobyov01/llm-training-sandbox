#!/usr/bin/env python3
"""
–ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è LLM Training Sandbox

–≠—Ç–æ—Ç —Å–∫—Ä–∏–ø—Ç –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç –æ—Å–Ω–æ–≤–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –ø—Ä–æ–µ–∫—Ç–∞
"""

import torch
from model import SimpleTransformer
from dataset import TinyStoriesDataset

def demo_model():
    """–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –º–æ–¥–µ–ª–∏"""
    print("=== –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ ===")
    
    # –°–æ–∑–¥–∞–µ–º –º–æ–¥–µ–ª—å
    model = SimpleTransformer(
        vocab_size=100256,
        d_model=512,
        nhead=8,
        num_layers=6,
        max_len=512
    )
    
    print(f"–ú–æ–¥–µ–ª—å —Å–æ–∑–¥–∞–Ω–∞: {sum(p.numel() for p in model.parameters()):,} –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤")
    
    # –¢–µ—Å—Ç–æ–≤—ã–π forward pass
    batch_size, seq_len = 2, 128
    input_ids = torch.randint(0, 1000, (batch_size, seq_len))
    attention_mask = torch.ones_like(input_ids)
    
    with torch.no_grad():
        logits = model(input_ids, attention_mask)
    
    print(f"–í—Ö–æ–¥: {input_ids.shape} -> –í—ã—Ö–æ–¥: {logits.shape}")
    print("‚úì –ú–æ–¥–µ–ª—å —Ä–∞–±–æ—Ç–∞–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ\n")


def demo_dataset():
    """–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –¥–∞—Ç–∞—Å–µ—Ç–∞"""
    print("=== –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –¥–∞—Ç–∞—Å–µ—Ç–∞ ===")
    
    try:
        # –°–æ–∑–¥–∞–µ–º –¥–∞—Ç–∞—Å–µ—Ç
        dataset = TinyStoriesDataset(max_length=128)
        print(f"–î–∞—Ç–∞—Å–µ—Ç –∑–∞–≥—Ä—É–∂–µ–Ω: {len(dataset)} –ø—Ä–∏–º–µ—Ä–æ–≤")
        
        # –ü–æ–ª—É—á–∞–µ–º –æ–¥–∏–Ω –ø—Ä–∏–º–µ—Ä
        sample = dataset[0]
        print(f"–ü—Ä–∏–º–µ—Ä:")
        print(f"  input_ids: {sample['input_ids'].shape}")
        print(f"  attention_mask: {sample['attention_mask'].shape}")
        print(f"  labels: {sample['labels'].shape}")
        print("‚úì –î–∞—Ç–∞—Å–µ—Ç —Ä–∞–±–æ—Ç–∞–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ\n")
        
    except Exception as e:
        print(f"‚ö†Ô∏è  –î–∞—Ç–∞—Å–µ—Ç –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω (–≤–æ–∑–º–æ–∂–Ω–æ, –Ω–µ—Ç –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–∞): {e}\n")


def demo_training_command():
    """–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –∫–æ–º–∞–Ω–¥ –∑–∞–ø—É—Å–∫–∞"""
    print("=== –ö–æ–º–∞–Ω–¥—ã –∑–∞–ø—É—Å–∫–∞ ===")
    
    commands = [
        "# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π",
        "pip install -r requirements.txt",
        "",
        "# –û–¥–Ω–æ GPU",
        "python train.py --batch_size 4 --num_epochs 1",
        "",
        "# DDP –Ω–∞ 2 GPU",
        "./run_training.sh 2",
        "",
        "# DDP –Ω–∞ 4 GPU —Å –ø—Ä–æ—Ñ–∏–ª–∏—Ä–æ–≤–∞–Ω–∏–µ–º",
        "./run_training.sh 4",
        "",
        "# –ü—Ä–æ—Å–º–æ—Ç—Ä –ø—Ä–æ—Ñ–∏–ª–∏—Ä–æ–≤–∞–Ω–∏—è",
        "tensorboard --logdir=./profiler_logs"
    ]
    
    for cmd in commands:
        print(cmd)
    
    print("\n‚úì –í—Å–µ –∫–æ–º–∞–Ω–¥—ã –≥–æ—Ç–æ–≤—ã –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é\n")


if __name__ == "__main__":
    print("üöÄ LLM Training Sandbox - –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è\n")
    
    demo_model()
    demo_dataset()
    demo_training_command()
    
    print("üéâ –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")
    print("–î–ª—è —Ä–µ–∞–ª—å–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –∑–∞–ø—É—Å—Ç–∏—Ç–µ: ./run_training.sh 2")
